import pandas as pd
import os
import time
from GPT_Labeler import cleanse_reviews  # ë¼ë²¨ë§ í•¨ìˆ˜ (ì•ˆì •ì„± ê°•í™” ë²„ì „)

# === ì„¤ì • ===
csv_input_path = 'data/merged_result.csv'
csv_output_path = 'data/labeling_result.csv'

CHUNK_SIZE = 40  # A: í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì¥ ìˆ˜
BATCH_SIZE = 20    # B: GPT í˜¸ì¶œ ë‹¨ìœ„

# === ì…ë ¥ ë°ì´í„° ë¡œë“œ ===
df = pd.read_csv(csv_input_path)
content = list(df['content'])
total = len(content)

# === ì´ë¯¸ ì²˜ë¦¬ëœ ê°œìˆ˜ í™•ì¸ ===
if os.path.exists(csv_output_path):
    processed_df = pd.read_csv(csv_output_path)
    start_idx = len(processed_df)
    print(f"âœ… ì´ì „ì— {start_idx}ê°œ ì²˜ë¦¬ë¨. ì´ì–´ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
else:
    start_idx = 0
    print("ğŸš€ ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")

# === ì²­í¬ë³„ ì²˜ë¦¬ ===
for chunk_start in range(start_idx, total, CHUNK_SIZE):
    chunk_end = min(chunk_start + CHUNK_SIZE, total)
    chunk = content[chunk_start:chunk_end]
    labels = []

    print(f"\nğŸ”„ {chunk_start} ~ {chunk_end} ë¬¸ì¥ ì²˜ë¦¬ ì¤‘...")

    for i in range(0, len(chunk), BATCH_SIZE):
        sub_chunk = chunk[i:i + BATCH_SIZE]
        try:
            batch_labels = cleanse_reviews(sub_chunk)
        except Exception as e:
            print(f"[Error] ì²­í¬ {i} ~ {i+BATCH_SIZE} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            batch_labels = [1] * len(sub_chunk)  # fallback

        labels.extend(batch_labels)

    # === ê²°ê³¼ ì €ì¥ ===
    chunk_df = pd.DataFrame({
        'content': chunk,
        'label': labels # feedback_label': labels
    })

    # append ëª¨ë“œë¡œ ì €ì¥
    if not os.path.exists(csv_output_path):
        chunk_df.to_csv(csv_output_path, index=False, encoding='utf-8-sig')
    else:
        chunk_df.to_csv(csv_output_path, mode='a', header=False, index=False, encoding='utf-8-sig')

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {chunk_start} ~ {chunk_end} ë¬¸ì¥")

    # ì§€ì—° ì£¼ê¸° (ì›í•˜ë©´ ë¹„í™œì„±í™” ê°€ëŠ¥)
    time.sleep(3)

